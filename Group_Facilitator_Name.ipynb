{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35df81f-b1a4-4d36-89e1-c57e3756dd35",
   "metadata": {},
   "source": [
    "# Lending Club Case Study\n",
    "## by Ankit Kumar Surana\n",
    "\n",
    "## Introduction\n",
    "As a worker of a consumer finance company that specialises in lending different kinds of loans to urban clients, part of my job is to facilitate loan approval decision-making by evaluating application profiles and identifying hazards related to loan payback potential. To do this, I would need to analyze data in \"loan.csv\", which contains historical information about past loan applicants with default status information. This means finding patterns that indicate the applicant is likely to default, which in turn enables taking further action, such as denying a loan, adjusting the loan amount, or applying higher interest rates to risky applicants.\n",
    "\n",
    "Through the analysis, I aim to understand consumer and loan attributes affecting the customer's tendency to default, and also to find the driving factors, or variables, behind loan defaults. The company can then use such knowledge to improve its portfolio and risk assessment strategies.\n",
    "\n",
    "## Preliminary Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eea562-d6df-4806-98fc-6c389cdfe7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import regex as re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32839add-7c5e-4d39-8bb7-66c569dc7cfa",
   "metadata": {},
   "source": [
    "# Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8888e7-cfce-4e61-b49e-5ad9e22f0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4afd0-3161-4e48-9679-748d4ec92c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high-level overview of data shape and composition\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbe845-a8ef-477f-8df0-e958b087bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff426d3-ffe3-472f-ad83-d1bb45487c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6812026-539c-4cf3-bc76-a49065169749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Dictionary\n",
    "data_dictionary = pd.read_excel('Data_Dictionary.xlsx')\n",
    "data_dictionary = data_dictionary.dropna(axis=0, how=\"any\")\n",
    "data_dictionary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da41154-12d3-4a0e-98ad-a73222d82010",
   "metadata": {},
   "source": [
    "# Assessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e56568-7e37-481d-9c6b-3db8f1a26e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicated value\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8ff0c-063b-491c-b2e6-6db198069f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null value for each column\n",
    "null_cols = df.columns[df.isnull().all(axis=0)].tolist()\n",
    "\n",
    "print(f\"List of columns with NULL's : \\n\\n {null_cols} \\n\")\n",
    "print(f\"Count of columns having all NULL values : {len(null_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95dbe3-4af5-4de6-9b1d-c486c4323780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the uniqueness of a column in data frame\n",
    "\n",
    "uniq_list = df.columns[(df.nunique() == 1)].tolist()\n",
    "print(\"\\nList of columns that have same value for all records : \", uniq_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4632a1cc-1574-41c2-8f78-a88b610661ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns that have Categorical variables in the dataset\n",
    "\n",
    "# Function that lists the categorical_values in a column\n",
    "def categorical_values(column_list):\n",
    "    for column in column_list:\n",
    "         print(f\"<<<<< {column} >>>>> \\n\")\n",
    "         print(df[column].value_counts(), \"\\n\")\n",
    "\n",
    "column_list = ['term', 'grade', 'sub_grade', 'verification_status', 'loan_status', 'purpose', \"home_ownership\"]\n",
    "categorical_values(column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aca542-7b25-4199-9149-2d0ccf47fe70",
   "metadata": {},
   "source": [
    ">1) Columns used post-loan approval need to be dropped.\n",
    ">2) Some rows have loan_status as \"Current\".\n",
    ">3) Some columns have all NULL values.\n",
    ">4) Some columns are textual and masked and do not aid in the analysis.\n",
    ">5) Some columns have the same values across all rows of the dataset.\n",
    ">6) For the columns where the data has a % symbol in it, clean the data.\n",
    ">7) Removing the alphabet from the sub-grade.\n",
    ">8) The values in the emp_length need to be cleaned.\n",
    ">9) Round off the amount values to the nearest 2 digits.\n",
    ">10) Some columns with date values are of object data type.\n",
    ">11) Convert the data type to float after cleaning the data with % in them.\n",
    ">12) Convert the data type to categorical for columns that have categorical values.\n",
    ">13) Break down the date columns to smaller metrics like month, and year.\n",
    ">14) Deriving a categorical column form loan_amnt.\n",
    ">15) Handle the missing values: imputing/ deleting.\n",
    ">16) Renaming the columns : Abbrevations etc.\n",
    ">17) Treating the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a72010-b1b4-4c12-b6c6-4bebc047f410",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17443b77-eb3e-4d67-a0bd-55357ef93c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abbc1fd-5403-4a0f-97d8-a709423534a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7545b-6633-4b0f-a4a8-ba36c603db90",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac649d64-1900-4a12-8bcf-1149c6d513c2",
   "metadata": {},
   "source": [
    "> 1) Dropping columns used post-loan approval that would not aid in analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9516ff82-d47f-4ee1-a854-e9b334140149",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e6fba2-4eb3-462a-a51a-9c94f611761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in data_dictionary not available in the data\n",
    "data_dictionary[data_dictionary.LoanStatNew.isin(df.columns.tolist()) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58efba-a171-4c3f-ba26-840da0024cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the data_dictionary\n",
    "data_dictionary = data_dictionary[~data_dictionary.LoanStatNew.isin(df.columns.tolist()) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f0fe0-253c-48ee-bbde-64ff070b4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15cc5c-61d9-4f6f-87f9-7ddd26fb3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_loan_cols = ['earliest_cr_line', 'collection_recovery_fee' , 'last_credit_pull_d',\n",
    " 'delinq_2yrs', 'inq_last_6mths', 'last_pymnt_amnt', 'last_pymnt_d', \n",
    " 'open_acc', 'pub_rec', 'recoveries', 'revol_bal', 'revol_util', \n",
    " 'total_acc', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', \n",
    " 'total_rec_late_fee' ]\n",
    "\n",
    "# Updating the data_dictionary of useful columns\n",
    "data_dictionary = data_dictionary[data_dictionary.LoanStatNew.isin(post_loan_cols) == False].reset_index(drop=True)\n",
    "\n",
    "#Dropping columns used post-loan approval\n",
    "df_clean = df_clean.drop(post_loan_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c7d899-78ef-4396-b97e-4565035906e8",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336bd01-771b-4efa-a1ca-5bbdce344f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating df_clean for post-approval columns\n",
    "df_clean.columns[df_clean.columns.isin(post_loan_cols) == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3192f-8d20-40f2-8eee-20955ab36644",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12120d8-5a2f-4d65-9449-90b1049f0847",
   "metadata": {},
   "source": [
    ">2) Dropping rows that have loan_status as \"Current\".\n",
    ">3) Dropping the columns having all NULL values.\n",
    ">4) Dropping additional columns that do not aid in analysis : ''id', 'member_id', 'url', 'title', 'emp_title',  'desc', 'zip_code'\n",
    ">5) Dropping the columns that have same values in all rows of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207630d1-e022-4a38-b039-960e7cccbd84",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945fb92-84ac-4b5b-b02d-e92f88dbcb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows that have loan_status as \"Current\".\n",
    "df_clean = df_clean[df_clean['loan_status']!='Current']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf037a-3f2b-42d4-a537-ab189d2ba5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding columns available in the data whose all the values are null\n",
    "data_dictionary = data_dictionary[data_dictionary.LoanStatNew.isin(df_clean.columns[df_clean.isna().all()].tolist()) == False].reset_index(drop=True)\n",
    "\n",
    "# Dropping all the columns having NULL values\n",
    "df_clean = df_clean.dropna(axis = 1, how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b175c6-b00e-4463-b356-6820700a6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping any additional columns that do not aid in analysis.\n",
    "col_drop = ['id', 'member_id', 'url', 'title', 'emp_title', 'desc', 'zip_code']\n",
    "\n",
    "#Update the data_dictionary by removing the col_drop\n",
    "data_dictionary = data_dictionary[data_dictionary.LoanStatNew.isin(col_drop) == False].reset_index(drop=True)\n",
    "\n",
    "df_clean = df_clean.drop(col_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d936a8-b0fd-4a84-a23c-71ef5fe84a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the columns that have same values in all the rows of the dataset.\n",
    "uniq_val_cols = df_clean.columns[(df_clean.nunique() == 1)].tolist()\n",
    "\n",
    "#Update the data_dictionary by removing the uniq_val_cols \n",
    "data_dictionary = data_dictionary[data_dictionary.LoanStatNew.isin(uniq_val_cols) == False].reset_index(drop=True)\n",
    "\n",
    "df_clean = df_clean.drop(uniq_val_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe44ba-01cc-446b-af41-4f5388986b1c",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37a0a0-7770-4aab-bb2c-09e02599ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating if there are any rows that have loan_status as \"Current\".\n",
    "df_clean[df_clean['loan_status']=='Current']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d8be2-1d0c-4ead-8697-f5b53f82d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating if there is any column that has all NULL values\n",
    "df_clean.columns[df_clean.isnull().all(axis=0)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca0d6f-05eb-47c4-b8da-9aad63e81118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating if there are columns that have same values for all rows in the dataset.\n",
    "df_clean.columns[(df_clean.nunique() == 1)].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1629ed1f-3cb4-4e1a-81e1-d4ab4d94d32d",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f7a46-e02c-455b-a50f-771372e6190f",
   "metadata": {},
   "source": [
    ">6) Removing the % symbol from the \"int_rate\" column.\n",
    ">7) Removing the alphabet from the sub-grade.\n",
    ">8) Cleaning the values in \"emp_length\" column by removing the \"years\" from the data and converting \"10+\" to 10 and \"< 1\" to 0.\n",
    ">9) Round off the amount to nearest 2 digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3bcbf2-1408-4d01-bb19-1f0686da3681",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3475f0ec-5ca6-44b3-895a-f2930b45cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the % symbol from the int_rate column.\n",
    "\n",
    "df_clean['int_rate'] = df_clean['int_rate'].str.split(\"%\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f22cd9-141f-4417-bd16-ae147230c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the alphabet from the sub_grade.\n",
    "df_clean['sub_grade'] = df_clean['sub_grade'].str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0fde0-68ee-4c3a-ae02-61073b4124a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the values in \"emp_length\" column by removing the \"years\" from the data and converting \"10+\" to 10 and \"< 1\" to 0.\n",
    "\n",
    "df_clean.emp_length = df_clean.emp_length.str.split(\"year\").str[0]\n",
    "df_clean.emp_length = df_clean.emp_length.str.replace(\"+\",\"\").str.replace(\"< 1\",\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecef7405-490c-49d3-8c1a-d3367a86b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round off the amounts to nearest 2 digits\n",
    "\n",
    "rnd_cols = ['loan_amnt','funded_amnt','funded_amnt_inv','installment','annual_inc']\n",
    "\n",
    "# Converting all the columns to float and then rounding to 2 digits\n",
    "df_clean[rnd_cols] = df_clean[rnd_cols].astype(\"float\").round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a3ab9-6e99-4f67-abfa-0ed82824decf",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602f004-cf57-470f-bd68-f7603100ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating the int_rate column.\n",
    "df_clean.int_rate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c7702-2af9-49b1-8d3f-2b24bc05f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating the emp_length column.\n",
    "df_clean.emp_length.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51318c6-18c1-410e-a586-8f2342315f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating the amount and rate columns data type.\n",
    "print(df_clean.info())\n",
    "\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9a8b2-ae0f-4d5a-bf5f-cf52f9a688c3",
   "metadata": {},
   "source": [
    "> 10) Converting the data type of date columns from object to datetime.\n",
    "> 11) Converting the data type of rate columns to float : 'int_rate'\n",
    "> 12) Convert the data type to categorical for columns that have categorical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55ded84-c673-422b-bedc-56f7037afe2f",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c5550-127b-4981-8972-5dcc63e058d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to date type\n",
    "for col in df_clean.columns.to_list():\n",
    "    if re.match('(.*_d$|.*cr_line$)', col):\n",
    "        df_clean[col] = pd.to_datetime(df_clean[col],format=\"%b-%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba139a6-1d50-4291-8fe3-c3088a806855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to float type\n",
    "df_clean['int_rate'] = df_clean['int_rate'].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868ab6a-1a40-4814-b8a0-3057b500037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to Categories\n",
    "columns = ['emp_length', 'home_ownership', 'grade', 'sub_grade', 'loan_status', 'term', 'verification_status']\n",
    "df_clean[columns] = df_clean[columns].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6ca1c-a0d2-4fac-828c-47f6ffeb332d",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0927e156-dc7f-42cb-a970-7a51a88b96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating data types of date and rate columns\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb0df2-4d25-43a2-b9b0-572210c62a0a",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b1eb6-2dd7-40e6-95df-466a519bdaa6",
   "metadata": {},
   "source": [
    "> 13)  Breakdown the date column into smaller metrics like : years and months\n",
    "> 14) Deriving a categorical column loan_amnt_b from loan_amnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6160a-7060-44f3-a890-cb4968750d8b",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52039549-76b8-4033-b015-60a869632681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breaking down the date column into smaller metrics like : years and months\n",
    "\n",
    "df_clean['issue_d_year'] = df_clean['issue_d'].dt.year\n",
    "df_clean['issue_d_month'] = df_clean['issue_d'].dt.month_name()\n",
    "# df_clean.drop('issue_d', axis=1, inplace=True)\n",
    "\n",
    "# Converting the data type to categorical\n",
    "issue_d_month_range = df_clean.issue_d_month.unique().tolist()\n",
    "issue_d_month_range.reverse()\n",
    "df_clean['issue_d_month'] = pd.Categorical(df_clean['issue_d_month'], issue_d_month_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197f24b-f3c4-4bcb-b88c-02250f2fa2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deriving categorical column loan_amount_b from loan amount\n",
    "bins = [bin for bin in range(0,35000,5000)]\n",
    "labels = [f\"{bins[i]}-{bins[i+1]}\" for i in range(len(bins)-1)]\n",
    "df_clean['loan_amnt_b'] = pd.cut(df_clean['loan_amnt'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580d674-6f70-41f2-9a9d-cbcc64b3ff5c",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f41d0-9ec2-47a5-a33d-b6defdfa0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validating the smaller metrics like : years and months of a date column\n",
    "df_clean[['issue_d_year','issue_d_month']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002bf9ae-a8a1-42e6-a446-b54f6c490b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating categorical column loan_amount_b derived from loan amount\n",
    "df_clean['loan_amnt_b'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02cca62-bef1-4747-a619-3112658cbae6",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef116e2-06ca-42f3-9059-011ad01cfe99",
   "metadata": {},
   "source": [
    "> 15) Handle the missing values: imputing/ deleting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6636e-eb01-4306-af64-581b05f8676d",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b3945-23a0-4c56-b049-8db42b9af078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns having NULL/NaN values \n",
    "round(df_clean.isnull().sum().sort_values(ascending=False)/len(df)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407c169-71e6-4041-95df-5fb6fc315e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns mths_since_last_record and mths_since_last_delinq can be dropped as more than 60% of the data is NULL/ NaN\n",
    "drop_cols = ['mths_since_last_record','mths_since_last_delinq']\n",
    "df_clean = df_clean.drop(drop_cols, axis=1)\n",
    "\n",
    "#Update the data_dictionary by removing the drop_cols \n",
    "data_dictionary = data_dictionary[data_dictionary.LoanStatNew.isin(drop_cols) == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b6d7a-8892-4d35-b62d-0d802c35cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values for emp_length\n",
    "print(round(df_clean.emp_length.value_counts()/len(df)*100,2))\n",
    "\n",
    "mode_value = df_clean.emp_length.mode()[0]\n",
    "print(\"\\nMode value for emp_length : \", mode_value)\n",
    "\n",
    "# Imputing the NULL/ NaN values with mode value for emp_length\n",
    "df_clean.emp_length.fillna(mode_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a13a6-ea39-404c-8634-b2c2ec0e7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values for pub_rec_bankruptcies\n",
    "print(round(df_clean.pub_rec_bankruptcies.value_counts()/len(df)*100,2))\n",
    "\n",
    "mode_value = df_clean.pub_rec_bankruptcies.mode()[0]\n",
    "print(\"\\nMode value for pub_rec_bankruptcies : \", mode_value)\n",
    "\n",
    "#More than 90% of the records have pub_rec_bankruptcies as 0.0. Hence imputing the value with 0.0\n",
    "df_clean.pub_rec_bankruptcies.fillna(mode_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542eb4a-8736-44c7-ad1d-3f9ca8c05d54",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2e3b4-8d47-45f5-8289-20525f505a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating the handling of missing values\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d8ddb-613a-4c75-a694-8feff6407f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9fd36e-289f-4ca4-89c3-54de5bda494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1f76c-4043-42c9-b92e-8bcc9a43f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb1b933-480f-4728-bd10-9c84a010b1fb",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9cdfc-b6e3-47b1-af85-0e36ca533fae",
   "metadata": {},
   "source": [
    "> 16) Renaming the abbrevated column : dti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb23723e-1c04-4ebe-a4e8-926699be2bfe",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33465638-79c3-4a83-a39b-0326abbdd0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the dti to debt_to_income\n",
    "new_mapping = {'dti': 'debt_to_income'}\n",
    "                        \n",
    "df_clean = df_clean.rename(columns=new_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b683c62c-6e2c-425a-b182-1a0a7ffe0163",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8459708-f5b4-4506-81bf-d224d04408e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196b520a-fdf5-48fb-84bb-30d00dd4b6df",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff499e6-a06a-4334-9076-467786d07a1f",
   "metadata": {},
   "source": [
    "> 17) Indetifying and Handling the outliers/extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8dbed-e348-49d1-91fb-591534854775",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2db528-9a9b-4766-abeb-d313f4f2af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating outliers\n",
    "\n",
    "def outlier_plot(dataframe, column_list): \n",
    "    \"\"\"\n",
    "    Plots boxplots to examine outliers in the specified columns of the given dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (DataFrame): The pandas DataFrame containing the data.\n",
    "    column_list (list): A list of column names to examine for outliers.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for index, value in enumerate(column_list): \n",
    "        title_name = f\"Outlier Examination for {value} column\"    \n",
    "        plt.subplot(2, 3, index+1)\n",
    "        plt.subplots_adjust(hspace = .4, wspace = .4)\n",
    "        plt.title(title_name, fontsize=7)  \n",
    "        dataframe[value].plot(figsize=(16,8), kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f4c77e-9ae7-449c-9cff-a517ea844b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['loan_amnt', 'funded_amnt','funded_amnt_inv','installment','annual_inc']\n",
    "outlier_plot(df_clean, cols)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6608bb2-52d7-4867-8d0c-0b08cc6d25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the upper quartile to 80% as most outliers lay outside the 80% range. \n",
    "Q1 = df_clean[cols].quantile(0.05)\n",
    "Q3 = df_clean[cols].quantile(0.80)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df_clean = df_clean[~((df_clean[cols] < (Q1 - 1.5 * IQR)) | (df_clean[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cafa47-351d-467e-90d4-a962f7202b2a",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c0cea-16e6-409d-9c75-a051e7c77328",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_plot(df_clean, cols)\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f8eaf-05e7-4b12-87ab-66ed3abaf08e",
   "metadata": {},
   "source": [
    "### Below is the data dictionary for the remaining columns on which we will conduct the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da8bf2-9327-47b1-9062-21413818dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47377822-1138-4e6b-be67-02d292fa75f0",
   "metadata": {},
   "source": [
    "### Below is the segregation of Customer and Loan attributes post Data Assessment and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef8da8-4b9e-4754-a953-669b4d1437c1",
   "metadata": {},
   "source": [
    "__Customer Attributes__\n",
    "> 1. annual_inc → Float Data Type\n",
    "> 2. debt_to_income → Float Data Type\n",
    "> 3. pub_rec_bankruptcies → Float Data Type\n",
    "> 4. home_ownership → Categorical Data Type\n",
    "> 5. addr_state → String Data Type\n",
    "> 6. emp_length → Categorical Data Type\n",
    "\n",
    "__Loan Attributes__\n",
    "> 1. term → Categorical Data Type\n",
    "> 2. issue_d → DateTime Data Type\n",
    "> 3. grade → Categorical Data Type\n",
    "> 4. sub_grade → Categorical Data Type\n",
    "> 5. verification_status → Categorical Data Type\n",
    "> 6. loan_status → Categorical Data Type\n",
    "> 7. purpose → Categorical Data Type\n",
    "> 8. loan_amnt → Float Data Type\n",
    "> 9. funded_amnt → Float Data Type\n",
    "> 10. funded_amnt_inv → Float Data Type\n",
    "> 11. int_rate → Float Data Type\n",
    "> 12. installment → Float Data Type\n",
    "\n",
    "\n",
    "__Derived Attributes__\n",
    "> 1. issue_d_year → Integer Data Type\n",
    "> 2. issue_d_month → Categorical Data Type\n",
    "> 3. loan_amnt_b → Categorical Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e4bdf-b86e-4e7f-9bc9-225b372aef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7b7bcd-270c-4a16-8892-82f219e7aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns  = df_clean.select_dtypes(exclude=['object','datetime','category']).columns.tolist()\n",
    "categorical_columns = df_clean.select_dtypes(include=['category']).columns.tolist()\n",
    "extra_columns = df_clean.select_dtypes(include=['object','datetime']).columns.tolist()\n",
    "print(\"numeric_columns : \", numeric_columns)\n",
    "print(\"categorical_columns : \", categorical_columns)\n",
    "print(\"extra_columns : \", extra_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f1187-65ea-47c9-bafd-5b6dd646bb10",
   "metadata": {},
   "source": [
    "# Exploratory Data Analisys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae082ba4-142b-4daa-96f4-a54733ccd3af",
   "metadata": {},
   "source": [
    "#### __Univariate Analysis__ \n",
    " → Mean, Median, Max, Min, Std, Variance, Count\n",
    " → Distribution ( Histogram, CountPlot, BoxPlot)\n",
    "#### __Bivariate Analysis__\n",
    " → Relationship Between 2 Variables ( ScatterPlot, BoxPlot, BarPlot etc)\n",
    "#### __Multivariate Analysis__\n",
    " → Relationship Between more variables ( Heatmap etc.)m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc83ea8-59a2-42fd-94c3-a22fb00257b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns  = df_clean.select_dtypes(exclude=['object','datetime','category']).columns.tolist()\n",
    "cateogrical_columns = df_clean.select_dtypes(include=['category']).columns.tolist()\n",
    "extra_columns = df_clean.select_dtypes(include=['object','datetime']).columns.tolist()\n",
    "print(\"numerical_columns -> \", numeric_columns)\n",
    "print(\"cateogrical_columns -> \", cateogrical_columns)\n",
    "print(\"extra_columns -> \", extra_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca4e458-0cb3-4841-a1a2-06736eda897d",
   "metadata": {},
   "source": [
    "## Univariate Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e25af-655b-4ba5-aaed-90b399cc19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-ordering categorical variables\n",
    "\n",
    "# Sorting emp_length order\n",
    "emp_length_order = df_clean['emp_length'].unique().tolist()\n",
    "emp_length_order = sorted(emp_length_order, key=lambda emp_length_order: int(emp_length_order))\n",
    "df_clean['emp_length'] = df_clean['emp_length'].cat.reorder_categories(emp_length_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4d250-5a87-4067-9db0-8c532340bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for performing univariate analysis on a specified column in a DataFrame.\n",
    "class UnivariateAnalysis:\n",
    "    # Initializes the UnivariateAnalysis object with the given DataFrame.\n",
    "    def __init__(self, dataframe,column_name):\n",
    "       \n",
    "        self.dataframe = dataframe\n",
    "        self.column_name = column_name\n",
    "        print(f\"Initiating detailed analysis of {column_name}...\")\n",
    "        print(f\"\\nStatistical summary for {self.column_name}:\\n{self.dataframe[self.column_name].describe()}\")\n",
    "        mode = self.dataframe[self.column_name].mode()[0]\n",
    "        print(f\"\\nThe mode of {self.column_name} is: {mode}\\n\")\n",
    "\n",
    "    # Performs univariate analysis on the specified column with bins.\n",
    "    def analyze_with_bins(self, bin_range=None, discrete=False):\n",
    "        sns.set_style('whitegrid')\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        sns.histplot(data=self.dataframe, x=self.column_name, bins=bin_range, discrete=discrete, kde=True, color='skyblue')\n",
    "        plt.title(f'Distribution of {self.column_name} with Bins', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        plt.xlabel(self.column_name, fontsize=14)\n",
    "        plt.ylabel('Frequency', fontsize=14)\n",
    "        plt.xticks(bin_range, rotation=45, fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Performs univariate analysis on the specified column without bins.\n",
    "    def analyze_without_bins(self):\n",
    "        sns.set_style('whitegrid')\n",
    "    \n",
    "        fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        sns.histplot(data=self.dataframe, x=self.column_name, ax=ax[0], kde=True, color='salmon')\n",
    "        ax[0].set_title(f'{self.column_name} Histogram', fontsize=16, fontweight='bold')\n",
    "    \n",
    "        sns.boxplot(data=self.dataframe, y=self.column_name, ax=ax[1], palette='muted')\n",
    "        ax[1].set_title(f'{self.column_name} Box Plot', fontsize=16, fontweight='bold')\n",
    "    \n",
    "        for axis in ax:\n",
    "            axis.set_xlabel(self.column_name, fontsize=14)\n",
    "            axis.set_ylabel('Frequency', fontsize=14)\n",
    "            axis.tick_params(axis=\"x\", rotation=45, labelsize=12)\n",
    "            axis.tick_params(axis=\"y\", labelsize=12)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b4fe9b-6450-4606-ba02-72f6ba770680",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis = UnivariateAnalysis(df_clean, 'loan_amnt')\n",
    "univariate_analysis.analyze_without_bins()\n",
    "univariate_analysis.analyze_with_bins(bin_range=range(0, 35000, 5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c38bb-2c80-4df4-80c4-86116dee9825",
   "metadata": {},
   "source": [
    "##### __Observation__ : From the above distribution we can see that most of the loan application amount were between 5000-10000, followed by 0-5000 and then 10000-15000. However the mean for the loan amount is 10678 and the mode is 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad176ad-827c-4ca3-8132-9a8a3c96da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis = UnivariateAnalysis(df_clean, 'annual_inc')\n",
    "univariate_analysis.analyze_without_bins()\n",
    "univariate_analysis.analyze_with_bins(bin_range=range(0, 240000, 20000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c40a28-6b47-4e93-8e01-ef0e3fc6c421",
   "metadata": {},
   "source": [
    "##### __Observation__ : From the above distribution we can see that most of the loan application where from customers whose annual income lies between 30000-60000. The mean of annual income of the customers is 63517 and the mode is 60000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e1d50-2077-44dd-b00b-c777e7d2e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis = UnivariateAnalysis(df_clean, 'int_rate')\n",
    "univariate_analysis.analyze_without_bins()\n",
    "univariate_analysis.analyze_with_bins(bin_range=range(5, 25, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d070f7-aa13-46f0-a58e-16eef233b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis = UnivariateAnalysis(df_clean, 'debt_to_income')\n",
    "univariate_analysis.analyze_without_bins()\n",
    "univariate_analysis.analyze_with_bins(bin_range=range(0, 30, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d5a41-8331-47c1-a074-238349a5a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categorical_columns:\n",
    "    univariate_analysis = UnivariateAnalysis(df_clean, category)\n",
    "    univariate_analysis.analyze_without_bins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220acbd-9ec4-497f-82f5-4a24d9ff5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_range = df_clean.issue_d_month.unique().tolist()\n",
    "univariate_analysis = UnivariateAnalysis(df_clean, 'issue_d_month')\n",
    "univariate_analysis.analyze_with_bins(bin_range=month_range, discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51530d-c0df-4484-9711-eb442f347534",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_range = df_clean.issue_d_year.unique().tolist()\n",
    "univariate_analysis = UnivariateAnalysis(df_clean, 'issue_d_year')\n",
    "univariate_analysis.analyze_with_bins(bin_range=year_range, discrete=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c35bc71-9ebb-4a5f-bb5e-61ec433dc7cf",
   "metadata": {},
   "source": [
    "## Segmented Univariate Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c86317-dd21-401d-af46-786b03ffcfd0",
   "metadata": {},
   "source": [
    "#### Segmenting the loan status into 'fully_paid' and 'charged_off' and analyzing the impact of other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff8bf8-1989-4361-bcf2-ded693313db4",
   "metadata": {},
   "source": [
    "> Loan Status → Fully Paid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f47dd1-7798-4008-bd41-d4292553ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fully_paid = df_clean[df_clean['loan_status'] == 'Fully Paid']\n",
    "df_fully_paid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11f735-9f40-4067-8cd5-03be7b24d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis = UnivariateAnalysis(df_fully_paid, 'loan_amnt')\n",
    "univariate_analysis.analyze_without_bins()\n",
    "univariate_analysis.analyze_with_bins(bin_range=range(1000, 38000, 3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d28bd-8130-492d-b127-82a9371c219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis = UnivariateAnalysis(df_fully_paid, 'int_rate')\n",
    "univariate_analysis.analyze_without_bins()\n",
    "univariate_analysis.analyze_with_bins(bin_range=range(1, 38, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b74ad-7837-4eba-9086-3429dfd178b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis = UnivariateAnalysis(df_fully_paid, 'annual_inc')\n",
    "univariate_analysis.analyze_without_bins()\n",
    "univariate_analysis.analyze_with_bins(bin_range=range(0, 220000, 8000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caeba2b-85e4-4ebf-a739-d2f946525a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['loan_amnt_b', 'grade', 'emp_length','verification_status', 'home_ownership']\n",
    "for category in cat_columns:\n",
    "    univariate_analysis = UnivariateAnalysis(df_fully_paid, category)\n",
    "    univariate_analysis.analyze_without_bins()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89b30f-0b77-433f-8fd1-da079ae3e2b6",
   "metadata": {},
   "source": [
    "> Loan Status → Charged Off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b7507-7247-4c2d-85ae-fb0b331f1f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_charged_off = df_clean[df_clean['loan_status'] == 'Charged Off']\n",
    "df_charged_off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis = UnivariateAnalysis(df_charged_off, 'loan_amnt')\n",
    "univariate_analysis.analyze_without_bins()\n",
    "univariate_analysis.analyze_with_bins(bin_range=range(1000, 38000, 3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis = UnivariateAnalysis(df_charged_off, 'int_rate')\n",
    "univariate_analysis.analyze_without_bins()\n",
    "univariate_analysis.analyze_with_bins(bin_range=range(1, 38, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daebb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis = UnivariateAnalysis(df_charged_off, 'annual_inc')\n",
    "univariate_analysis.analyze_without_bins()\n",
    "univariate_analysis.analyze_with_bins(bin_range=range(0, 220000, 8000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['loan_amnt_b', 'grade', 'emp_length','verification_status', 'home_ownership']\n",
    "for category in cat_columns:\n",
    "    univariate_analysis = UnivariateAnalysis(df_charged_off, category)\n",
    "    univariate_analysis.analyze_without_bins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f9707-6ed9-4d2c-94b6-554d746336b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ed0692-e565-431e-80a3-30047b67a8b7",
   "metadata": {},
   "source": [
    "# Bivariate Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada108bf-c115-4fa5-ad23-8f916f09a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for performing bivariate analysis on a DataFrame.\n",
    "\n",
    "class BivariateAnalysis:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    # Generates a scatter plot for two specified columns in a DataFrame.\n",
    "    def scatter_plot(self, x_column, y_column, marker_size=10, alpha=0.2, color='orange'):\n",
    "\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.scatterplot(data=self.dataframe, x=x_column, y=y_column, s=marker_size, alpha=alpha, color=color)\n",
    "\n",
    "        # Set plot title and labels\n",
    "        plt.title(f'Scatter Plot: {x_column} vs {y_column}', fontsize=13)\n",
    "        plt.xlabel(x_column, fontsize=12)\n",
    "        plt.ylabel(y_column, fontsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Generates a boxplot for a categorical column against a numerical column for bivariate analysis.\n",
    "    def boxplot(self, categorical_column, numerical_column, palette='pastel'):\n",
    "\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.boxplot(data=self.dataframe, x=categorical_column, y=numerical_column, palette=palette)\n",
    "\n",
    "        # Set plot title and labels\n",
    "        plt.title(f'Boxplot: {categorical_column} vs {numerical_column}', fontsize=13)\n",
    "        plt.xlabel(categorical_column, fontsize=12)\n",
    "        plt.ylabel(numerical_column, fontsize=12)\n",
    "\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31e839-896b-4490-8dc3-70e5581d03e9",
   "metadata": {},
   "source": [
    "### Bivariate Analysis - Numerical vs Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d25780-2e23-4ad8-9611-ff39cf7674d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate_analysis = BivariateAnalysis(df_clean)\n",
    "\n",
    "bivariate_analysis.scatter_plot('loan_amnt', 'int_rate', color='orange')\n",
    "bivariate_analysis.scatter_plot('loan_amnt', 'installment', color='#FF5733')\n",
    "bivariate_analysis.scatter_plot('loan_amnt', 'annual_inc', color='skyblue')\n",
    "bivariate_analysis.scatter_plot('loan_amnt', 'pub_rec_bankruptcies', color='green')\n",
    "bivariate_analysis.scatter_plot('annual_inc', 'int_rate', color='#8A2BE2')\n",
    "bivariate_analysis.scatter_plot('annual_inc', 'debt_to_income', color='pink')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf2c33-cec8-4e96-9e62-47de5b300c6c",
   "metadata": {},
   "source": [
    "### Bivariate Analysis - Categorical vs Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281334d-c508-4a03-93e8-92251aa5b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate_analysis = BivariateAnalysis(df_clean)\n",
    "\n",
    "bivariate_analysis.boxplot('term', 'loan_amnt', palette='deep')\n",
    "bivariate_analysis.boxplot('grade', 'loan_amnt', palette='muted')\n",
    "bivariate_analysis.boxplot('emp_length', 'loan_amnt', palette='pastel')\n",
    "bivariate_analysis.boxplot('loan_status', 'int_rate', palette='dark')\n",
    "bivariate_analysis.boxplot('grade', 'int_rate', palette='colorblind')\n",
    "bivariate_analysis.boxplot('verification_status', 'loan_amnt', palette='OrRd')\n",
    "bivariate_analysis.boxplot('home_ownership', 'loan_amnt', palette='YlOrRd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5620fc-662c-464b-8d57-00db29877a48",
   "metadata": {},
   "source": [
    "Here are the observations derived from the above analysis:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eaf960-e018-4395-88a2-4b81bf272dde",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe7a28-35a8-471e-a0d3-568b52048680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for performing multivariate analysis on a DataFrame.\n",
    "class MultivariateAnalysis:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    # Generates a heatmap for visualizing the correlation matrix of numerical columns in the DataFrame. \n",
    "    def heatmap(self, cmap='coolwarm'):\n",
    "        sns.set(style=\"white\")\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(self.dataframe.corr(), cmap=cmap, annot=True, fmt=\".2f\", linewidths=0.5)\n",
    "        plt.title('Correlation Matrix Heatmap', fontsize=16)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06850c-9060-49be-8160-ec03ca8ee0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a heatmap to visualize the correlation matrix of numerical columns in the DataFrame\n",
    "df_heatmap = df_clean[numerical_columns]\n",
    "multivariate_analysis = MultivariateAnalysis(df_heatmap)\n",
    "multivariate_analysis.heatmap()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
